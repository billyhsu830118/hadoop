{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install pywebhdfs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.display import display\n",
    "display(salaries.head())\n",
    "display(teams.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://pythonhosted.org/pywebhdfs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "import os\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = '/home/hduser/anaconda3/bin/python'\n",
    "# The value is the python command of the version required to start the master and worker in the Linux system\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = r\"C:\\Users\\billy\\anaconda3\\python.exe\"\n",
    "# The value is the spark directory in the local windows system\n",
    "os.environ['SPARK_HOME'] = 'C:/spark'\n",
    "# The value is the local IP, and the IP required to establish a connection, to prevent connection failure when multiple network cards\n",
    "#os.environ['SPARK_LOCAL_IP'] = '192.168.56.1'\n",
    "os.environ['HADOOP_HOME'] = \"D:/hadoop-3.3.0\"\n",
    "os.environ['HADOOP_CONF_DIR'] = \"/usr/local/hadoop/etc/hadoop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf  = pyspark.SparkConf().setAppName('sql').setMaster('spark://192.168.133.4:7077').set(\n",
    "    \"spark.submit.deployMode\",\"client\").set('spark.driver.memory','2g').set(\n",
    "        'spark.executor.memory', '2g').set('spark.executor.cores', 1).set(\n",
    "        'spark.network.timeout', 600).set('spark.executor.heartbeatInterval', 120).set(\n",
    "    'spark.cores.max', 4).set(\"spark.driver.host\",\"192.168.133.1\").set(\"spark.driver.port\",\"9999\")#.set('spark.python.profile','true')\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"hdfs://192.168.133.4:9000/user/hduser/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RawUserRDD = sc.textFile(path+\"data/u.data\")\n",
    "print(RawUserRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'196\\t242\\t3\\t881250949'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RawUserRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['196', '242', '3'],\n",
       " ['186', '302', '3'],\n",
       " ['22', '377', '1'],\n",
       " ['244', '51', '2'],\n",
       " ['166', '346', '1']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawRatings = RawUserRDD.map(lambda line:line.split(\"\\t\")[:3])\n",
    "rawRatings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('196', '242', '3'),\n",
       " ('186', '302', '3'),\n",
       " ('22', '377', '1'),\n",
       " ('244', '51', '2'),\n",
       " ('166', '346', '1')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 準備 ALS 需要的資料格式\n",
    "ratingsRDD = rawRatings.map(lambda x:(x[0],x[1],x[2]))\n",
    "ratingsRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numUsers: 943\n",
      "numMovies: 1682\n"
     ]
    }
   ],
   "source": [
    "# Check number of Users & Movies\n",
    "numUsers = ratingsRDD.map(lambda x:x[0]).distinct().count()\n",
    "print('numUsers: {}'.format(numUsers))\n",
    "numMovies = ratingsRDD.map(lambda x:x[1]).distinct().count()\n",
    "print('numMovies: {}'.format(numMovies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ALS.train(ratingsRDD,100,10,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=100, product=50, rating=5.264741865346331),\n",
       " Rating(user=100, product=205, rating=5.255808183772364),\n",
       " Rating(user=100, product=12, rating=5.248360601754374),\n",
       " Rating(user=100, product=408, rating=5.245821371231437),\n",
       " Rating(user=100, product=173, rating=5.214595123176999)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[Rating(user=550, product=200, rating=5.824029028146284),\n",
       " Rating(user=592, product=200, rating=5.613487663848079),\n",
       " Rating(user=686, product=200, rating=5.607321231537176),\n",
       " Rating(user=119, product=200, rating=5.459150811076884),\n",
       " Rating(user=939, product=200, rating=5.406562954822373)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.723600984798437"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommend for movies\n",
    "model.recommendProducts(100,5)\n",
    "# recommend for users\n",
    "model.recommendUsers(product=200,num=5)\n",
    "#predict rating of user:100 with movies 1141 \n",
    "model.predict(100,1141)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0',\n",
       " '2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0',\n",
       " '3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0',\n",
       " '4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0',\n",
       " '5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Copycat (1995)'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read movies data\n",
    "itemRDD = sc.textFile(path+\"data/u.item\")\n",
    "itemRDD.count()\n",
    "itemRDD.take(5)\n",
    "# split and take the information of the movies\n",
    "movieTitle = itemRDD.map(lambda line:line.split(\"|\")).map(lambda x:(int(x[0]),x[1])).collectAsMap()\n",
    "movieTitle[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:100, Recommend Product:Star Wars (1977), Recommend Rating:5.264741865346331\n",
      "User:100, Recommend Product:Patton (1970), Recommend Rating:5.255808183772364\n",
      "User:100, Recommend Product:Usual Suspects, The (1995), Recommend Rating:5.248360601754374\n",
      "User:100, Recommend Product:Close Shave, A (1995), Recommend Rating:5.245821371231437\n",
      "User:100, Recommend Product:Princess Bride, The (1987), Recommend Rating:5.214595123176999\n"
     ]
    }
   ],
   "source": [
    "def MovieRecommendation(model,movieTitle,inputUserID):\n",
    "    recommendMovie = model.recommendProducts(inputUserID,5)\n",
    "    for product in recommendMovie:\n",
    "        print('User:{}, Recommend Product:{}, Recommend Rating:{}'.format(product[0], movieTitle[product[1]],product[2]))  \n",
    "    return recommendMovie\n",
    "\n",
    "recommendMovie = MovieRecommendation(model,movieTitle,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommend Product:Copycat (1995) to User:332,  Recommend Rating:4.990003695073672\n",
      "Recommend Product:Copycat (1995) to User:256,  Recommend Rating:4.979165538453725\n",
      "Recommend Product:Copycat (1995) to User:270,  Recommend Rating:4.967893439611046\n",
      "Recommend Product:Copycat (1995) to User:546,  Recommend Rating:4.921540234611819\n",
      "Recommend Product:Copycat (1995) to User:907,  Recommend Rating:4.893374981388492\n"
     ]
    }
   ],
   "source": [
    "def UserRecommendation(model,movieTitle,inputMovie):\n",
    "    recommendUser = model.recommendUsers(product=inputMovie,num=5)\n",
    "    \n",
    "    for User in recommendUser:\n",
    "        print('Recommend Product:{} to User:{},  Recommend Rating:{}'.format(movieTitle[inputMovie],User[0],User[2]))  \n",
    "    return recommendUser\n",
    "\n",
    "recommendUser= UserRecommendation(model,movieTitle,5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if permission error\n",
    "hadoop fs -chmod 777 /user/hduser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models\n",
    "def SaveModel(sc):\n",
    "    try:\n",
    "        model.save(sc,path+\"ALSmodel\")\n",
    "        print(\"save Model as ALSmodel\")\n",
    "    except Exception:\n",
    "        print(\"Model is already exists, please delete first then save model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import MatrixFactorizationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=100, product=1120, rating=5.7459085417701665),\n",
       " Rating(user=100, product=1169, rating=5.432230823340303),\n",
       " Rating(user=100, product=863, rating=5.42895510992681),\n",
       " Rating(user=100, product=958, rating=5.217840353650354),\n",
       " Rating(user=100, product=1286, rating=5.206188785027526)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load models we saved\n",
    "model_test = MatrixFactorizationModel.load(sc,path+\"ALSmodel\")\n",
    "model_test.recommendProducts(100,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
